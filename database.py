# database.py
import csv
import json
import pymysql
import logging
from datetime import datetime
from pathlib import Path
from typing import Set, Dict, Any, List, Optional, Union
from config import DB_CONFIG, OUTPUT_DIR

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(OUTPUT_DIR / "crawler.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("database")

# å¿«å–å·²çˆ¬å–çš„URL
_url_cache: Optional[Set[str]] = None

def save_failed_url(url: str, reason: str, status_code: str = "Unknown") -> None:
    """
    è¨˜éŒ„çˆ¬å–å¤±æ•—çš„ URLï¼Œå­˜å…¥ MySQL å’Œ CSVã€‚

    Args:
        url (str): çˆ¬å–å¤±æ•—çš„ URLã€‚
        reason (str): å¤±æ•—çš„éŒ¯èª¤è¨Šæ¯ã€‚
        status_code (str): HTTP ç‹€æ…‹ç¢¼ï¼Œé è¨­ç‚º "Unknown"ã€‚
    """
    failed_csv_path = OUTPUT_DIR / "failed_urls.csv"

    # 1ï¸âƒ£ å­˜å…¥ CSV
    file_exists = failed_csv_path.exists()

    with open(failed_csv_path, "a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        if not file_exists:
            writer.writerow(["url", "reason", "status_code", "failed_time"])  # å¯«å…¥æ¨™é ­
        writer.writerow([url, reason, status_code, datetime.now().strftime("%Y-%m-%d %H:%M:%S")])
    logger.error(f"âŒ å·²è¨˜éŒ„å¤±æ•— URL: {url}, åŸå› : {reason}, ç‹€æ…‹ç¢¼: {status_code}")

    # 2ï¸âƒ£ å­˜å…¥ MySQL
    connection = None
    try:
        connection = pymysql.connect(**DB_CONFIG)
        cursor = connection.cursor()

        sql = """
        INSERT INTO failed_crawls (url, reason, status_code, failed_time)
        VALUES (%s, %s, %s, %s)
        ON DUPLICATE KEY UPDATE
        reason=VALUES(reason),
        status_code=VALUES(status_code),
        failed_time=VALUES(failed_time);
        """

        cursor.execute(sql, (url, reason, status_code, datetime.now().strftime("%Y-%m-%d %H:%M:%S")))
        connection.commit()
        logger.info(f"âœ… å¤±æ•— URL å­˜å…¥ MySQL: {url}")

    except pymysql.Error as e:
        logger.error(f"âŒ MySQL å­˜å…¥å¤±æ•— URL æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    finally:
        if connection:
            cursor.close()
            connection.close()

def save_permanent_failure(
    url: str, 
    error_category: str, 
    error_message: str, 
    status_code: Optional[int] = None, 
    site_name: str = "", 
    retry_count: int = 0,
    extra_data: Optional[Dict[str, Any]] = None
) -> bool:
    """
    å°‡æ°¸ä¹…å¤±æ•—çš„ URL ä¿å­˜åˆ°æ•¸æ“šåº«
    
    Args:
        url: å¤±æ•—çš„ URL
        error_category: éŒ¯èª¤é¡åˆ¥
        error_message: éŒ¯èª¤è¨Šæ¯
        status_code: HTTP ç‹€æ…‹ç¢¼
        site_name: ç«™é»åç¨±
        retry_count: é‡è©¦æ¬¡æ•¸
        extra_data: é¡å¤–æ•¸æ“š
        
    Returns:
        bool: æ“ä½œæ˜¯å¦æˆåŠŸ
    """
    permanent_failures_csv_path = OUTPUT_DIR / "permanent_failures.csv"
    file_exists = permanent_failures_csv_path.exists()
    
    # 1ï¸âƒ£ å­˜å…¥ CSV
    try:
        with open(permanent_failures_csv_path, "a", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            if not file_exists:
                writer.writerow([
                    "url", "error_category", "error_message", "status_code", 
                    "site_name", "retry_count", "extra_data", "failed_time"
                ])
                
            # å°‡é¡å¤–æ•¸æ“šè½‰æ›ç‚ºJSONå­—ç¬¦ä¸²
            extra_data_str = json.dumps(extra_data, ensure_ascii=False) if extra_data else ""
            
            writer.writerow([
                url, 
                error_category, 
                error_message[:500],  # é¿å…è¨Šæ¯éé•· 
                status_code or "Unknown", 
                site_name,
                retry_count,
                extra_data_str,
                datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            ])
        logger.warning(f"âš ï¸ å·²è¨˜éŒ„æ°¸ä¹…å¤±æ•— URL: {url}, é¡åˆ¥: {error_category}, é‡è©¦æ¬¡æ•¸: {retry_count}")
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜æ°¸ä¹…å¤±æ•— URL åˆ° CSV æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    # 2ï¸âƒ£ å­˜å…¥ MySQL
    connection = None
    try:
        # å°‡é¡å¤–æ•¸æ“šè½‰æ›ç‚ºJSONå­—ç¬¦ä¸²
        extra_data_json = json.dumps(extra_data, ensure_ascii=False) if extra_data else None
        
        connection = pymysql.connect(**DB_CONFIG)
        cursor = connection.cursor()

        # æª¢æŸ¥æ°¸ä¹…å¤±æ•—è¡¨æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨å‰‡å‰µå»º
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS permanent_failures (
            id INT AUTO_INCREMENT PRIMARY KEY,
            url VARCHAR(1000) NOT NULL,
            error_category VARCHAR(50) NOT NULL,
            error_message TEXT NOT NULL,
            status_code VARCHAR(50),
            site_name VARCHAR(100) NOT NULL,
            retry_count INT NOT NULL DEFAULT 0,
            extra_data TEXT,
            failed_at DATETIME NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE KEY(url(255))
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
        """)
        connection.commit()

        # æ’å…¥æ°¸ä¹…å¤±æ•—è¨˜éŒ„
        sql = """
        INSERT INTO permanent_failures
        (url, error_category, error_message, status_code, site_name, retry_count, extra_data, failed_at)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
        ON DUPLICATE KEY UPDATE
        error_category=VALUES(error_category),
        error_message=VALUES(error_message),
        status_code=VALUES(status_code),
        site_name=VALUES(site_name),
        retry_count=VALUES(retry_count),
        extra_data=VALUES(extra_data),
        failed_at=VALUES(failed_at);
        """

        cursor.execute(sql, (
            url, 
            error_category, 
            error_message, 
            str(status_code) if status_code else "Unknown", 
            site_name,
            retry_count,
            extra_data_json,
            datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        ))
        connection.commit()
        logger.info(f"âœ… æ°¸ä¹…å¤±æ•— URL å­˜å…¥ MySQL: {url}")
        return True

    except pymysql.Error as e:
        logger.error(f"âŒ MySQL å­˜å…¥æ°¸ä¹…å¤±æ•— URL æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False

    finally:
        if connection:
            cursor.close()
            connection.close()

def get_permanent_failures(site_name: Optional[str] = None) -> List[Dict[str, Any]]:
    """
    ç²å–æ°¸ä¹…å¤±æ•—çš„URLåˆ—è¡¨
    
    Args:
        site_name: ç«™é»åç¨± (å¯é¸)
        
    Returns:
        List[Dict[str, Any]]: æ°¸ä¹…å¤±æ•—URLåˆ—è¡¨
    """
    connection = None
    try:
        connection = pymysql.connect(**DB_CONFIG)
        cursor = connection.cursor(pymysql.cursors.DictCursor)  # ä½¿ç”¨å­—å…¸æ¸¸æ¨™

        # æŸ¥è©¢SQL
        if site_name:
            sql = "SELECT * FROM permanent_failures WHERE site_name = %s ORDER BY failed_at DESC"
            cursor.execute(sql, (site_name,))
        else:
            sql = "SELECT * FROM permanent_failures ORDER BY failed_at DESC"
            cursor.execute(sql)

        results = cursor.fetchall()
        
        # è™•ç†çµæœ
        processed_results = []
        for row in results:
            # è½‰æ› extra_data JSON å­—ç¬¦ä¸²ç‚ºå­—å…¸
            if row['extra_data'] and isinstance(row['extra_data'], str):
                try:
                    row['extra_data'] = json.loads(row['extra_data'])
                except json.JSONDecodeError:
                    row['extra_data'] = {}
            
            # æ ¼å¼åŒ–æ—¥æœŸ/æ™‚é–“
            if 'failed_at' in row and row['failed_at']:
                row['failed_at'] = row['failed_at'].strftime("%Y-%m-%d %H:%M:%S")
            if 'created_at' in row and row['created_at']:
                row['created_at'] = row['created_at'].strftime("%Y-%m-%d %H:%M:%S")
                
            processed_results.append(row)
        
        logger.info(f"ğŸ” ç²å–äº† {len(processed_results)} å€‹æ°¸ä¹…å¤±æ•—URL")
        return processed_results
    
    except pymysql.Error as e:
        logger.error(f"âŒ ç²å–æ°¸ä¹…å¤±æ•—URLæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return []

    finally:
        if connection:
            cursor.close()
            connection.close()

def clear_permanent_failures(site_name: Optional[str] = None) -> bool:
    """
    æ¸…é™¤æ°¸ä¹…å¤±æ•—çš„URLè¨˜éŒ„
    
    Args:
        site_name: ç«™é»åç¨± (å¯é¸)ï¼Œè‹¥æœªæä¾›å‰‡æ¸…é™¤æ‰€æœ‰è¨˜éŒ„
        
    Returns:
        bool: æ“ä½œæ˜¯å¦æˆåŠŸ
    """
    connection = None
    try:
        connection = pymysql.connect(**DB_CONFIG)
        cursor = connection.cursor()

        if site_name:
            sql = "DELETE FROM permanent_failures WHERE site_name = %s"
            cursor.execute(sql, (site_name,))
            affected_rows = cursor.rowcount
            connection.commit()
            logger.info(f"ğŸ§¹ å·²æ¸…é™¤ {site_name} ç«™é»çš„ {affected_rows} å€‹æ°¸ä¹…å¤±æ•—è¨˜éŒ„")
        else:
            sql = "DELETE FROM permanent_failures"
            cursor.execute(sql)
            affected_rows = cursor.rowcount
            connection.commit()
            logger.info(f"ğŸ§¹ å·²æ¸…é™¤æ‰€æœ‰ {affected_rows} å€‹æ°¸ä¹…å¤±æ•—è¨˜éŒ„")
        
        return True
    
    except pymysql.Error as e:
        logger.error(f"âŒ æ¸…é™¤æ°¸ä¹…å¤±æ•—è¨˜éŒ„æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False

    finally:
        if connection:
            cursor.close()
            connection.close()

def save_to_mysql(df) -> bool:
    """
    æ‰¹é‡å­˜å…¥ MySQLï¼Œå…è¨±ç›¸åŒ URL æ’å…¥å¤šç­†æ•¸æ“šã€‚
    
    Args:
        df: éœ€è¦å­˜å…¥çš„æ•¸æ“š DataFrameã€‚
        
    Returns:
        bool: æ“ä½œæ˜¯å¦æˆåŠŸ
    """
    if df.empty:
        logger.warning("âš ï¸ DataFrame ç‚ºç©ºï¼Œæ²’æœ‰æ•¸æ“šå­˜å…¥ MySQLã€‚")
        return False

    connection = None
    try:
        connection = pymysql.connect(**DB_CONFIG)
        cursor = connection.cursor()

        # é©—è­‰å¿…è¦æ¬„ä½æ˜¯å¦å­˜åœ¨
        required_columns = ["site_id", "website_category", "scraped_time", "site", "title", "content", "url"]
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            logger.error(f"âŒ ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_columns}")
            return False

        # æ¸…ç†æ•¸æ“š - ç¢ºä¿å­—ç¬¦ä¸²æ¬„ä½ä¸æ˜¯ None
        for col in ["title", "content", "description", "keywords", "url"]:
            if col in df.columns:
                df[col] = df[col].fillna("").astype(str)

        sql = """
        INSERT INTO crawl_data 
        (site_id, website_category, scraped_time, site, title, content, url, description, keywords)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s);
        """

        # æº–å‚™æ‰¹é‡æ’å…¥æ•¸æ“š
        data_to_insert = []
        for _, row in df.iterrows():
            # æª¢æŸ¥å…§å®¹é•·åº¦ï¼Œé¿å…è¶…å‡ºè³‡æ–™åº«æ¬„ä½é™åˆ¶
            content = row["content"]
            if len(content) > 65535:  # TEXT é¡å‹çš„é™åˆ¶
                content = content[:65535]
                logger.warning(f"âš ï¸ URL: {row['url']} å…§å®¹è¢«æˆªæ–·ï¼ŒåŸé•·åº¦: {len(row['content'])}")
            
            data_to_insert.append((
                int(row["site_id"]),
                row["website_category"],
                row["scraped_time"],
                row["site"],
                row["title"],
                content,
                row["url"],
                row.get("description", ""),
                row.get("keywords", ""),
            ))

        # æ‰¹é‡åŸ·è¡Œæ’å…¥
        cursor.executemany(sql, data_to_insert)
        connection.commit()
        logger.info(f"âœ… {len(data_to_insert)} ç­†æ•¸æ“šæˆåŠŸå­˜å…¥ MySQLï¼")
        
        # æ›´æ–°å¿«å–
        global _url_cache
        if _url_cache is not None:
            _url_cache.update([row["url"] for _, row in df.iterrows()])
            
        return True

    except pymysql.Error as e:
        logger.error(f"âŒ MySQL éŒ¯èª¤: {e}")
        return False

    finally:
        if connection:
            cursor.close()
            connection.close()


def get_existing_urls() -> Set[str]:
    """
    å¾ MySQL è®€å–å·²å­˜å…¥çš„ URLï¼Œå›å‚³ `set` ä»¥ä¾¿å¿«é€Ÿéæ¿¾ã€‚
    ä½¿ç”¨å¿«å–æ©Ÿåˆ¶é¿å…é »ç¹æŸ¥è©¢è³‡æ–™åº«ã€‚

    Returns:
        set: å·²ç¶“å­˜å…¥ MySQL çš„ URL é›†åˆã€‚
    """
    global _url_cache
    
    # å¦‚æœå¿«å–å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›
    if _url_cache is not None:
        logger.info(f"ğŸ” ä½¿ç”¨URLå¿«å–ï¼Œå…± {len(_url_cache)} å€‹URLã€‚")
        return _url_cache
    
    connection = None
    try:
        connection = pymysql.connect(**DB_CONFIG)
        cursor = connection.cursor()

        sql = "SELECT url FROM crawl_data"
        cursor.execute(sql)

        _url_cache = {row[0] for row in cursor.fetchall()}
        logger.info(f"ğŸ” å¾è³‡æ–™åº«è®€å–ï¼Œå·²å­˜åœ¨ {len(_url_cache)} ç¯‡æ–‡ç« ï¼Œå°‡è·³éçˆ¬å–ã€‚")
        return _url_cache

    except pymysql.Error as e:
        logger.error(f"âŒ MySQL æŸ¥è©¢ URL éŒ¯èª¤: {e}")
        return set()

    finally:
        if connection:
            cursor.close()
            connection.close()


def clear_url_cache() -> None:
    """æ¸…é™¤ URL å¿«å–ï¼Œå¼·åˆ¶ä¸‹æ¬¡å¾è³‡æ–™åº«è®€å–"""
    global _url_cache
    _url_cache = None
    logger.info("ğŸ§¹ å·²æ¸…é™¤ URL å¿«å–")


def init_database() -> bool:
    """
    åˆå§‹åŒ–è³‡æ–™åº«è¡¨çµæ§‹ï¼Œå¦‚æœè¡¨ä¸å­˜åœ¨å‰‡å‰µå»º
    
    Returns:
        bool: æ“ä½œæ˜¯å¦æˆåŠŸ
    """
    connection = None
    try:
        connection = pymysql.connect(
            host=DB_CONFIG["host"],
            user=DB_CONFIG["user"],
            password=DB_CONFIG["password"]
        )
        cursor = connection.cursor()
        
        # å‰µå»ºè³‡æ–™åº«ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        cursor.execute(f"CREATE DATABASE IF NOT EXISTS {DB_CONFIG['database']} CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci")
        cursor.execute(f"USE {DB_CONFIG['database']}")
        
        # å‰µå»ºçˆ¬èŸ²æ•¸æ“šè¡¨
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS crawl_data (
            id INT AUTO_INCREMENT PRIMARY KEY,
            site_id INT NOT NULL,
            website_category VARCHAR(50) NOT NULL,
            scraped_time DATETIME NOT NULL,
            site VARCHAR(100) NOT NULL,
            title VARCHAR(500) NOT NULL,
            content TEXT NOT NULL,
            url VARCHAR(1000) NOT NULL,
            description TEXT,
            keywords TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            INDEX(url(255)),
            INDEX(site_id)
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
        """)
        
        # å‰µå»ºçˆ¬å–å¤±æ•—è¨˜éŒ„è¡¨
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS failed_crawls (
            id INT AUTO_INCREMENT PRIMARY KEY,
            url VARCHAR(1000) NOT NULL,
            reason TEXT NOT NULL,
            status_code VARCHAR(50) NOT NULL,
            failed_time DATETIME NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE KEY(url(255))
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
        """)
        
        # å‰µå»ºæ°¸ä¹…å¤±æ•—è¨˜éŒ„è¡¨
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS permanent_failures (
            id INT AUTO_INCREMENT PRIMARY KEY,
            url VARCHAR(1000) NOT NULL,
            error_category VARCHAR(50) NOT NULL,
            error_message TEXT NOT NULL,
            status_code VARCHAR(50),
            site_name VARCHAR(100) NOT NULL,
            retry_count INT NOT NULL DEFAULT 0,
            extra_data TEXT,
            failed_at DATETIME NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE KEY(url(255))
        ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
        """)
        
        connection.commit()
        logger.info("âœ… è³‡æ–™åº«è¡¨çµæ§‹åˆå§‹åŒ–æˆåŠŸ")
        return True
        
    except pymysql.Error as e:
        logger.error(f"âŒ è³‡æ–™åº«åˆå§‹åŒ–å¤±æ•—: {e}")
        return False
        
    finally:
        if connection:
            cursor.close()
            connection.close()

def get_failure_stats() -> Dict[str, Any]:
    """
    ç²å–å¤±æ•—ä»»å‹™çš„çµ±è¨ˆä¿¡æ¯
    
    Returns:
        Dict[str, Any]: çµ±è¨ˆä¿¡æ¯å­—å…¸
    """
    connection = None
    try:
        connection = pymysql.connect(**DB_CONFIG)
        cursor = connection.cursor()
        
        # ç²å–å¸¸è¦å¤±æ•—çµ±è¨ˆ
        cursor.execute("SELECT COUNT(*) FROM failed_crawls")
        failed_count = cursor.fetchone()[0]
        
        # ç²å–æ°¸ä¹…å¤±æ•—çµ±è¨ˆ
        cursor.execute("SELECT COUNT(*) FROM permanent_failures")
        permanent_count = cursor.fetchone()[0]
        
        # æŒ‰éŒ¯èª¤é¡åˆ¥çµ±è¨ˆæ°¸ä¹…å¤±æ•—
        cursor.execute("""
        SELECT error_category, COUNT(*) as count 
        FROM permanent_failures 
        GROUP BY error_category 
        ORDER BY count DESC
        """)
        category_stats = {row[0]: row[1] for row in cursor.fetchall()}
        
        # æŒ‰ç«™é»çµ±è¨ˆæ°¸ä¹…å¤±æ•—
        cursor.execute("""
        SELECT site_name, COUNT(*) as count 
        FROM permanent_failures 
        GROUP BY site_name 
        ORDER BY count DESC
        """)
        site_stats = {row[0]: row[1] for row in cursor.fetchall()}
        
        # æŒ‰ç‹€æ…‹ç¢¼çµ±è¨ˆ
        cursor.execute("""
        SELECT status_code, COUNT(*) as count 
        FROM permanent_failures 
        GROUP BY status_code 
        ORDER BY count DESC
        """)
        status_stats = {row[0]: row[1] for row in cursor.fetchall()}
        
        # æœ€è¿‘çš„å¤±æ•—
        cursor.execute("""
        SELECT url, error_category, site_name, failed_at 
        FROM permanent_failures 
        ORDER BY failed_at DESC 
        LIMIT 5
        """)
        recent_failures = []
        for row in cursor.fetchall():
            recent_failures.append({
                "url": row[0],
                "error_category": row[1],
                "site_name": row[2],
                "failed_at": row[3].strftime("%Y-%m-%d %H:%M:%S") if row[3] else None
            })
        
        return {
            "total_failed": failed_count,
            "total_permanent_failed": permanent_count,
            "by_category": category_stats,
            "by_site": site_stats,
            "by_status": status_stats,
            "recent_failures": recent_failures
        }
        
    except pymysql.Error as e:
        logger.error(f"âŒ ç²å–å¤±æ•—çµ±è¨ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return {
            "error": str(e)
        }
        
    finally:
        if connection:
            cursor.close()
            connection.close()